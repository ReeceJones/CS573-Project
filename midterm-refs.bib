
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }
 
 
@article{RSSurvey,
title = {Recommendation systems: Principles, methods and evaluation},
journal = {Egyptian Informatics Journal},
volume = {16},
number = {3},
pages = {261-273},
year = {2015},
issn = {1110-8665},
doi = {https://doi.org/10.1016/j.eij.2015.06.005},
url = {https://www.sciencedirect.com/science/article/pii/S1110866515000341},
author = {F.O. Isinkaye and Y.O. Folajimi and B.A. Ojokoh},
keywords = {Collaborative filtering, Content-based filtering, Hybrid filtering technique, Recommendation systems, Evaluation}
}

@InProceedings{RSArticle,
author="Renuka, S.
and Raj Kiran, G. S. S.
and Rohit, Palakodeti",
editor="Jeena Jacob, I.
and Kolandapalayam Shanmugam, Selvanayaki
and Piramuthu, Selwyn
and Falkowski-Gilski, Przemyslaw",
title="An Unsupervised Content-Based Article Recommendation System Using Natural Language Processing",
booktitle="Data Intelligence and Cognitive Informatics",
year="2021",
publisher="Springer Singapore",
address="Singapore",
pages="165--180",
abstract="Recommendation system is a system that recommends things which are of interest to the user. This paper discusses two approaches based on content-based recommendation systems. The two approaches involve retrieving similar articles by means of cosine similarity and clustering, later the results of the respective approaches are compared. The text data with which this paper deals with comprises of two hundred and thirty Web articles related to various disciplines of machine learning and data science such as natural language processing, reinforcement learning, and deep learning. The data preprocessing steps involved in the methodology are removal of stopwords and word vectorization using TF-IDF. Utilizing cosine similarity, K-means, and agglomerative clustering methods to retrieve articles of user interest and relevance is based on the articles read by the user.",
isbn="978-981-15-8530-2"
}

@InProceedings{RSRecipe,
author="Ueta, Tsuguya
and Iwakami, Masashi
and Ito, Takayuki",
editor="Xiong, Hui
and Lee, W. B.",
title="A Recipe Recommendation System Based on Automatic Nutrition Information Extraction",
booktitle="Knowledge Science, Engineering and Management",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="79--90",
abstract="In this paper, we propose a goal-oriented recipe recommendation system that utilizes information about nutrition on the Internet. Our system enables users without knowledge about nutrition to search easily for recipes with natural language to improve specific health conditions. The natural language includes 'I want to cure my acne' and 'I want to recover from my fatigue'. To do that, we created a co-occurrence database that listed the co-occurrence of 45 common nutrients with nouns such as cold, acne, bone etc. Then we created a recipe database by collecting 800,000 recipes from www.cookpad.com the system and analyzed each recipe to calculate the amount of a nutrient in a dish. We compared the results of our system to the results we obtained by calculating the nutrient information manually. Evaluation was done on 1000 dishes. We measured the effectiveness of the system using F-Measure and the average F-measure was 0.64 respectively.",
isbn="978-3-642-25975-3"
}

@inproceedings{NLPRecipeGPT,
author = {H. Lee, Helena and Shu, Ke and Achananuparp, Palakorn and Prasetyo, Philips Kokoh and Liu, Yue and Lim, Ee-Peng and Varshney, Lav R.},
title = {RecipeGPT: Generative Pre-Training Based Cooking Recipe Generation and Evaluation System},
year = {2020},
isbn = {9781450370240},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3366424.3383536},
doi = {10.1145/3366424.3383536},
abstract = {Interests in the automatic generation of cooking recipes have been growing steadily
over the past few years thanks to a large amount of online cooking recipes. We present
RecipeGPT, a novel online recipe generation and evaluation system. The system provides
two modes of text generations: (1) instruction generation from given recipe title
and ingredients; and (2) ingredient generation from recipe title and cooking instructions.
Its back-end text generation module comprises a generative pre-trained language model
GPT-2 fine-tuned on a large cooking recipe dataset. Moreover, the recipe evaluation
module allows the users to conveniently inspect the quality of the generated recipe
contents and store the results for future reference. RecipeGPT can be accessed online
at &nbsp;https://recipegpt.org/ },
booktitle = {Companion Proceedings of the Web Conference 2020},
pages = {181–184},
numpages = {4},
keywords = {web application, natural language generation, recipe generation},
location = {Taipei, Taiwan},
series = {WWW '20}
}

@INPROCEEDINGS{NLPRecipeGM,  author={Reusch, Anja and Weber, Alexander and Thiele, Maik and Lehner, Wolfgang},  booktitle={2021 IEEE 37th International Conference on Data Engineering Workshops (ICDEW)},   title={RecipeGM: A Hierarchical Recipe Generation Model},   year={2021},  volume={},  number={},  pages={24-29},  doi={10.1109/ICDEW53142.2021.00012}}

@inproceedings{NLPSIMMR,
    title = "Predicting the Structure of Cooking Recipes",
    author = "Jermsurawong, Jermsak  and
      Habash, Nizar",
    booktitle = "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2015",
    address = "Lisbon, Portugal",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D15-1090",
    doi = "10.18653/v1/D15-1090",
    pages = "781--786",
}

@article{Recipe1M,
  title = {Recipe1M+: A Dataset for Learning Cross-Modal Embeddings for Cooking Recipes and Food Images},
  author = {Marin, Javier and Biswas, Aritro and Ofli, Ferda and Hynes, Nicholas and 
  Salvador, Amaia and Aytar, Yusuf and Weber, Ingmar and Torralba, Antonio},
  journal = {{IEEE} Trans. Pattern Anal. Mach. Intell.},
  year = {2019}
}

@misc{FoodComRecipe,
  author = {Shuyang Li},
  title = {{Food.com Recipes and Interactions}},
  howpublished = "\url{http://aiweb.techfak.uni-bielefeld.de/content/bworld-robot-control-software/}",
  year = {2019},
  doi = {10.34740/KAGGLE/DSV/783630}
}

@inproceedings{NIPS2017_6449f44a,
 author = {Ke, Guolin and Meng, Qi and Finley, Thomas and Wang, Taifeng and Chen, Wei and Ma, Weidong and Ye, Qiwei and Liu, Tie-Yan},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {LightGBM: A Highly Efficient Gradient Boosting Decision Tree},
 url = {https://proceedings.neurips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf},
 volume = {30},
 year = {2017}
}

@inproceedings{RPKmeans,
 author = {Rishabh Ahuja, Arun Solanki, Anand Nayyar},
 title = {Movie Recommender System Using K-Means Clustering AND K-Nearest NeighborR},
 url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8776969},
 year = {2019}
}
@inproceedings{RPSimilarity,
 author = {Mykhaylo Schwarz, Mykhaylo Lobur, Yuriy Stekh},
 title = {Analysis of the Effectiveness of Similarity Measures for Recommender Systems},
 url = {https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7916133},
 year = {2017}
}
@inproceedings{RPDM,
 author = {Jiawei Han, Micheline Kamber, Jian Pei},
 booktitle = {Data Mining (Third Edition)},
 publisher = {Morgan Kaufmann},
 url = {http://myweb.sabanciuniv.edu/rdehkharghani/files/2016/02/The-Morgan-Kaufmann-Series-in-Data-Management-Systems-Jiawei-Han-Micheline-Kamber-Jian-Pei-Data-Mining.-Concepts-and-Techniques-3rd-Edition-Morgan-Kaufmann-2011.pdf},
 year = {2012}
}
@inproceedings{RPL1Norm,
 author = {Gourav Jain, Tripti Mahara, Kuldeep Narayan Tripathi},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 title = {Measures for Collaborative Filtering-Based Recommender Systems},
 url = {https://books.google.com/books?hl=en&amp;lr=&amp;id=9aDSDwAAQBAJ&amp;oi=fnd&amp;pg=PA343&amp;dq=cosine+similarity+Euclidean+distance+rating+&amp;ots=k5mg-HnUhv&amp;sig=ndh1mdw1SaKe7VhcidMR8GdI2iM#v=onepage&amp;q=cosine\%20similarity\%20Euclidean\%20distance\%20rating&amp;f=false},
 year = {2020}
}

% Naive bayes classifier is recommended for text classification (Cooking duration prediction)
@article{CDPNaiveBayes,
author = {Domingos, Pedro and Pazzani, Michael},
title = {On the Optimality of the Simple Bayesian Classifier under Zero-One Loss},
year = {1997},
issue_date = {Nov./Dec. 1997},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {29},
number = {2–3},
issn = {0885-6125},
url = {https://doi.org/10.1023/A:1007413511361},
doi = {10.1023/A:1007413511361},
abstract = {The simple Bayesian classifier is known to be optimal when
attributes are independent given the class, but the question of whether
other sufficient conditions for its optimality exist has so far not been
explored. Empirical results showing that it performs surprisingly well in
many domains containing clear attribute dependences suggest that the answer
to this question may be positive. This article shows that, although the
Bayesian classifier‘s probability estimates are only optimal under quadratic
loss if the independence assumption holds, the classifier itself can be
optimal under zero-one loss (misclassification rate) even when this
assumption is violated by a wide margin. The region of quadratic-loss
optimality of the Bayesian classifier is in fact a second-order
infinitesimal fraction of the region of zero-one optimality. This implies
that the Bayesian classifier has a much greater range of applicability than
previously thought. For example, in this article it is shown to be optimal
for learning conjunctions and disjunctions, even though they violate the
independence assumption. Further, studies in artificial domains show that it
will often outperform more powerful classifiers for common training set
sizes and numbers of attributes, even if its bias is a
priori much less appropriate to the domain. This article‘s results
also imply that detecting attribute dependence is not necessarily the best
way to extend the Bayesian classifier, and this is also verified
empirically.},
journal = {Mach. Learn.},
month = {nov},
pages = {103–130},
numpages = {28},
keywords = {optimal classification, zero-one loss, Simple Bayesian classifier, naive Bayesian classifier, induction with attribute dependences}
}

% Porter stemmer was used for pre-processing for cooking duration task%
@article{Porter1980AnAF,
  title={An algorithm for suffix stripping},
  author={Martin F. Porter},
  journal={Program},
  year={1980},
  volume={40},
  pages={211-218}
}

@InProceedings{CDPImproveNaiveBayes,
author="Schneider, Karl-Michael",
editor="Gelbukh, Alexander",
title="Techniques for Improving the Performance of Naive Bayes for Text Classification",
booktitle="Computational Linguistics and Intelligent Text Processing",
year="2005",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="682--693",
abstract="Naive Bayes is often used in text classification applications and experiments because of its simplicity and effectiveness. However, its performance is often degraded because it does not model text well, and by inappropriate feature selection and the lack of reliable confidence scores. We address these problems and show that they can be solved by some simple corrections. We demonstrate that our simple modifications are able to improve the performance of Naive Bayes for text classification significantly.",
isbn="978-3-540-30586-6"
}

% Startegy to train language models for larger values of n
@inproceedings{RG_GrowingNGramModels,
author = {Siivola, Vesa and Pellom, Bryan},
year = {2005},
month = {09},
pages = {1309-1312},
title = {Growing an n-gram language model},
doi = {10.21437/Interspeech.2005-24}
}